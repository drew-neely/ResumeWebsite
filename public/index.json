[{"authors":["admin"],"categories":null,"content":"I am a Computer Scientist specializing in low level Computer Systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Computer Scientist specializing in low level Computer Systems.","tags":null,"title":"Drew Neely","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\n Create slides using Academic's Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":" Introduction The objective of this project is to discover features of numbers generated ‘randomly’ by a human and generated randomly by a computer that can be used to predict the creator of the ‘random’ number. To do this, I surveyed 10 people to produce 10 10-digit strings of random numbers. I also gathered some other potentially relevant information, then anonymized the data. The data collected from the 10 people are shown below.\nnumbers_wide \u0026lt;- read.csv(\u0026quot;random_human_numbers.csv\u0026quot;) head(numbers_wide) ## Name Human Gender Age Political.Party Studied.Science Seq.1 ## 1 A Yes Female 21 Democrat Yes 2789956111 ## 2 B Yes Female 21 Democrat Yes 4985720117 ## 3 C Yes Male 49 Republican Yes 6221014971 ## 4 D Yes Female 20 Democrat Yes 2438509376 ## 5 E Yes Male 21 Democrat Yes 1865318579 ## 6 F Yes Female 20 Democrat No 1547869073 ## Seq.2 Seq.3 Seq.4 Seq.5 Seq.6 Seq.7 ## 1 1366759287 7635557721 9422606787 5705422787 2967210348 9756780291 ## 2 6590031429 6404098972 2314564259 8712385119 1203343473 5645786902 ## 3 4179819803 2317891995 1908913123 5079181795 6481046253 2957108139 ## 4 1845910348 2071394705 1893526313 5724680516 2739152704 1637923840 ## 5 9987412378 1721834778 1321865554 1980874319 8700918782 1384794786 ## 6 5841290825 4613798534 6871045978 2103776154 9626598215 4065982138 ## Seq.8 Seq.9 Seq.10 ## 1 5497651238 4591268881 4295565751 ## 2 1985763498 7050413427 6802232476 ## 3 1221316015 4620378902 8763219721 ## 4 6932674084 6905183951 8390649135 ## 5 5431821870 8479871231 4798218976 ## 6 7596053467 9283153469 8218083509 I then used pivot_longer to make this data long.\nnumbers \u0026lt;- numbers_wide %\u0026gt;% pivot_longer(starts_with(\u0026quot;Seq\u0026quot;), values_to = \u0026quot;Number\u0026quot;, names_to = \u0026quot;Seq\u0026quot;, names_prefix = \u0026quot;Seq.\u0026quot;) head(numbers) ## # A tibble: 6 x 8 ## Name Human Gender Age Political.Party Studied.Science Seq Number ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 A Yes Female 21 Democrat Yes 1 2789956111 ## 2 A Yes Female 21 Democrat Yes 2 1366759287 ## 3 A Yes Female 21 Democrat Yes 3 7635557721 ## 4 A Yes Female 21 Democrat Yes 4 9422606787 ## 5 A Yes Female 21 Democrat Yes 5 5705422787 ## 6 A Yes Female 21 Democrat Yes 6 2967210348 I then added 100 computer-generated random 10-digit strings onto the end of the 100 human generated random strings.\nset.seed(666) for(i in 1:100) { num \u0026lt;- paste(sample(0:9, 10, replace = TRUE), collapse = \u0026#39;\u0026#39;) df \u0026lt;- data.frame(NA, \u0026quot;No\u0026quot;, NA, NA, NA, NA, NA, num) names(df) \u0026lt;- names(numbers) numbers \u0026lt;- rbind(numbers, df) } I then wrote the dataframe to a csv file and switched over to python to extract the features.\nwrite.csv(numbers, \u0026quot;random_numbers.csv\u0026quot;) I generated several features for each observation and exported a new csv file using the following python code.\nimport csv import statistics entries = [] # import csv csv.register_dialect(\u0026#39;myDialect\u0026#39;,delimiter = \u0026#39;,\u0026#39;,quoting=csv.QUOTE_ALL,skipinitialspace=True) with open(\u0026#39;random_numbers.csv\u0026#39;, \u0026#39;r\u0026#39;) as f: reader = csv.DictReader(f, dialect=\u0026#39;myDialect\u0026#39;) for row in reader: entries += [dict(row)] ###################################################################### def addFeatures(entry) : seq = entry[\u0026#39;Number\u0026#39;] while len(seq) \u0026lt; 10 : seq = \u0026#39;0\u0026#39; + seq # digit frequency max = 0 for d in range(0,10) : count = 0 for i in range(0, 10) : if str(d) == seq[i] : count += 1 entry[\u0026#39;count.\u0026#39;+str(d)] = count if count \u0026gt; max : max = count entry[\u0026#39;count.max.duplicates\u0026#39;] = max # number of consecutive numbers count = 0 for i in range(1, 10) : if int(seq[i]) == int(seq[i-1]) - 1 or int(seq[i]) == int(seq[i-1]) + 1 : count += 1 entry[\u0026#39;num.consecutive\u0026#39;] = count # derivative diff = [] for i in range(1, 10) : diff += [int(seq[i]) - int(seq[i-1])] deriv = statistics.mean(diff) entry[\u0026#39;derivative\u0026#39;] = int(deriv * 100) / 100 entry[\u0026#39;growth.direction\u0026#39;] = \u0026#39;Increase\u0026#39; if deriv \u0026gt; 0 else (\u0026#39;Decrease\u0026#39; if deriv \u0026lt; 0 else \u0026#39;Zero\u0026#39;) # mean sum = 0 for i in range(0, 10) : sum += int(seq[i]) entry[\u0026#39;mean\u0026#39;] = sum / 10 # standard deviation entry[\u0026#39;std.dev\u0026#39;] = int(statistics.stdev([int(seq[i]) for i in range(0, 10)]) * 1000) / 1000 # even and odd entry[\u0026#39;num.odd\u0026#39;] = len([int(seq[i]) for i in range(0, 10) if int(seq[i]) % 2 == 1]) entry[\u0026#39;num.even\u0026#39;] = len([int(seq[i]) for i in range(0, 10) if int(seq[i]) % 2 == 0]) return entry ###################################################################### # Generate features for i in range(0, len(entries)) : entries[i] = addFeatures(entries[i]) # Export csv with open(\u0026#39;random_numbers_with_features.csv\u0026#39;, mode=\u0026#39;w\u0026#39;) as csv_file: writer = csv.DictWriter(csv_file, fieldnames=entries[0].keys()) writer.writeheader() for i in range(0, len(entries)) : writer.writerow(entries[i]) The features generated include the following : frequency of each digit, the highest frequency of any digit, the number of consecutive digits, the derivative of the sequence, the sign of the derivative (categorical), the mean of the sequence, the standard deviation of the sequence, and the number of even and odd digits in the sequence.\nNow this csv can be re-imported into R.\nfeatures \u0026lt;- read.csv(\u0026#39;random_numbers_with_features.csv\u0026#39;) Then I can add a binary variable ‘Is.Human’ that is 1 if the sequence was generated by a human and 0 if the sequence was generated by a machine. I can also drop the variables I will not be using for testing.\nfeatures \u0026lt;- features %\u0026gt;% mutate(\u0026quot;Is.Human\u0026quot; = if_else(Human == \u0026quot;Yes\u0026quot;, 1, 0)) %\u0026gt;% select(-Name, -Human, -Gender, -Age, -Political.Party, -Studied.Science, -Seq, -Number) Finally I can randomize the order of the rows.\nset.seed(666) features \u0026lt;- features[sample(nrow(features)), ] Now the features dataset is complete!\nhead(features) ## count.0 count.1 count.2 count.3 count.4 count.5 count.6 count.7 ## 62 1 1 1 1 1 1 0 2 ## 126 2 2 0 0 1 0 3 0 ## 96 0 2 1 1 2 1 1 1 ## 139 0 2 1 0 0 0 1 1 ## 123 0 2 2 1 0 2 1 1 ## 28 1 4 2 1 0 1 1 0 ## count.8 count.9 count.max.duplicates num.consecutive derivative ## 62 1 1 2 3 0.11 ## 126 1 1 3 1 -0.66 ## 96 1 0 2 3 0.33 ## 139 2 3 3 1 0.11 ## 123 1 0 2 0 0.11 ## 28 0 0 4 3 0.44 ## growth.direction mean std.dev num.odd num.even Is.Human ## 62 Increase 4.6 3.098 6 4 1 ## 126 Decrease 4.1 3.381 3 7 0 ## 96 Increase 4.1 2.424 5 5 1 ## 139 Increase 6.0 3.366 6 4 0 ## 123 Increase 4.0 2.538 6 4 0 ## 28 Increase 2.2 1.932 6 4 1  MANOVA Test Because some subsets of the data can be used to perfectly predict other features of this data (for example, if we know the frequency of the numbers 0-8 in a sequence we can easily calculate the frequency of 9s, the mean, and the standard deviation), multiple Manovas must be done with different sets of variables. It is likely that this division suggests we have more features than are likely to be helpful in creating a model to predict the data, but we will ignore this in favor of simplicity.\nDigit Frequencies The first manova we shall run will test if the frequency of numbers in the sequence is significantly different between different sources of the sequence.\nfreqMan\u0026lt;-manova(cbind(count.0,count.1,count.2, count.3,count.4,count.5, count.6,count.7,count.8) ~ Is.Human, data=features) summary(freqMan) ## Df Pillai approx F num Df den Df Pr(\u0026gt;F) ## Is.Human 1 0.077249 1.7673 9 190 0.07681 . ## Residuals 198 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Since this is a relatively small dataset for what we are studying and the cost of a type 1 error (finding a non-predictor to be a predictor) is likely less than that of a type 2 error, we will use a relatively high significance threshold of 0.10.\nWith a p-value of 0.07681, the frequency of the numbers in the sequence is significant. As such, we must now run a multiple Anova tests to determine which features are significant predictors.\nsummary.aov(freqMan) ## Response count.0 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.005 0.00500 0.0067 0.9348 ## Residuals 198 147.390 0.74439 ## ## Response count.1 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.605 0.60500 0.8025 0.3714 ## Residuals 198 149.270 0.75389 ## ## Response count.2 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 2.645 2.64500 4.1449 0.04309 * ## Residuals 198 126.350 0.63813 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response count.3 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.72 0.7200 0.8893 0.3468 ## Residuals 198 160.30 0.8096 ## ## Response count.4 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.02 0.02000 0.0276 0.8681 ## Residuals 198 143.26 0.72354 ## ## Response count.5 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 2.42 2.42000 2.6995 0.102 ## Residuals 198 177.50 0.89646 ## ## Response count.6 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 2.205 2.20500 3.6581 0.05724 . ## Residuals 198 119.350 0.60278 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response count.7 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 3.125 3.12500 4.5742 0.03368 * ## Residuals 198 135.270 0.68318 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response count.8 : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.5 0.50000 0.6471 0.4221 ## Residuals 198 153.0 0.77273 summary(aov(count.9 ~ Is.Human, data = features)) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.04 0.0450 0.062 0.804 ## Residuals 198 144.71 0.7309 This tells us that the frequency of ‘2’, ‘6’, and ‘7’ are significantly different between computer generated random numbers and human generated random numbers.\nfeatures %\u0026gt;% group_by(Is.Human) %\u0026gt;% summarise(\u0026quot;count.2\u0026quot; = mean(count.2), \u0026quot;count.6\u0026quot; = mean(count.6), \u0026quot;count.7\u0026quot; = mean(count.7)) ## # A tibble: 2 x 4 ## Is.Human count.2 count.6 count.7 ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 0.88 1.02 0.82 ## 2 1 1.11 0.81 1.07 These results show that humans use more twos and sevens and fewer sixes. However, the results regarding the frequencies of twos and seven invite suspicion since we expect to see 1 as the mean count of every number generated by a computer, but the computer generated sequence frequencies differ from 1 by more than 10% when considering twos and sevens.\nA post-hoc t-test for the frequency of twos, sixes, and sevens is shown below (even though since there are only 2 categories in the Is.Human field this is kind of pointless)\npairwise.t.test(features$count.2, features$Is.Human, p.adj=\u0026quot;none\u0026quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: features$count.2 and features$Is.Human ## ## 0 ## 1 0.043 ## ## P value adjustment method: none pairwise.t.test(features$count.6, features$Is.Human, p.adj=\u0026quot;none\u0026quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: features$count.6 and features$Is.Human ## ## 0 ## 1 0.057 ## ## P value adjustment method: none pairwise.t.test(features$count.7, features$Is.Human, p.adj=\u0026quot;none\u0026quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: features$count.7 and features$Is.Human ## ## 0 ## 1 0.034 ## ## P value adjustment method: none  Distribution Properties Now we can test the other features of the sequence that were extracted.\ndistMan\u0026lt;-manova(cbind(count.max.duplicates, num.consecutive, derivative, growth.direction, mean, std.dev, num.even) ~ Is.Human, data=features) summary.aov(distMan) ## Response count.max.duplicates : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 7.22 7.2200 19.199 1.909e-05 *** ## Residuals 198 74.46 0.3761 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response num.consecutive : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 27.38 27.3800 15.452 0.0001169 *** ## Residuals 198 350.84 1.7719 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response derivative : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.128 0.12802 0.6849 0.4089 ## Residuals 198 37.008 0.18691 ## ## Response growth.direction : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.245 0.24500 0.5294 0.4677 ## Residuals 198 91.630 0.46278 ## ## Response mean : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.361 0.36125 0.5934 0.442 ## Residuals 198 120.533 0.60875 ## ## Response std.dev : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.629 0.62922 2.8836 0.09106 . ## Residuals 198 43.205 0.21821 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Response num.even : ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.12 0.1250 0.0544 0.8159 ## Residuals 198 455.27 2.2993 summary(aov(num.odd ~ Is.Human, data = features)) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## Is.Human 1 0.1 0.125 0.054 0.816 ## Residuals 198 455.3 2.299 From this we can see that there is a very significant difference between the two groups in terms of the variables count.max.duplicate (the highest count of the digits in the sequence), and num.consecutive (the number of consecutive numbers in the sequence). There is also a less significant difference between the two groups in terms of the variable std.dev (the standard deviation of the digits in the sequence).\nI will not include a post-hoc t-test for this set of variables since there are only two groups.\n Multiple Comparisons Correction In this analysis, 18 null hypothesis were tested. However, the largest subset of the variables tested which together do not perfectly predict any other variable in the subset (via linear combination) is of size 14. This excludes count.9, mean, num.even, and num.odd. This we will consider this analysis to consist of 14 comparisons.\nSince we picked a significance threshold of 0.10, the probability that any given test yields a type 1 error is 10%. Thus, the probability that there is a type 1 error across our 14 comparisons is 1 - (1 - 0.10)14 = 77%. This rather high, so to correct for multiple comparisons we will use the bonferroni correction. This requires us to divide our significance level by 14 in order to keep the probability of a type 1 error occuring at 10%. The new significance level after correcting for multiple comparisons is 7.143e-3.\n Significant Variables Using a corrected significance level of 7.143e-3, several variables which were before significant no longer are. The two explanatory variables which still have significant differences in the means between computer generated sequences and human generated sequences are count.max.duplicates (F = 19.199, p = 1.909e-5) and num.consecutive (F = 15.452, p = 1.1169e-4). Human generated sequences have significantly different highest-frequency of digits and number of consecutive digits compared to computer generated sequences.\nfeatures %\u0026gt;% mutate(\u0026quot;Source\u0026quot; = if_else(Is.Human == 1, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;)) %\u0026gt;% select(Source, count.max.duplicates, num.consecutive) %\u0026gt;% pivot_longer(c(count.max.duplicates, num.consecutive), names_to=\u0026quot;var\u0026quot;, values_to=\u0026quot;value\u0026quot;) %\u0026gt;% ggplot(aes(Source,value,fill=Source)) + scale_x_discrete(labels=c(\u0026quot;Human\u0026quot;,\u0026quot;Computer\u0026quot;))+ geom_bar(stat=\u0026quot;summary\u0026quot;) + geom_errorbar(stat=\u0026quot;summary\u0026quot;) + labs(title = \u0026quot;Means of significant variables\u0026quot;) + facet_wrap(~var, nrow=2) + coord_flip() + ylab(\u0026quot;\u0026quot;) + theme(legend.position = \u0026quot;none\u0026quot;)  Assumptions The assumption of random and independent observations was likely not very well met. The people surveyed to generate random numbers were not a random sample they were all people from my friend group and family. Additionally, each person surveyed generated multiple sequences. Since it is very possible that the features of the sequences generated by humans vary from person to person, the assumption of independent observations was not really met (I could test if there are any obviously significant differences between the features of the sequences generated by different people to explore this more, but I’m not going to).\n  Randomization Test To again test if together the distributions of count.max.duplicates and num.consecutive are significantly different for sequences of numbers generated by humans and by computers, I will perform a PERMANOVA test. This test works by calculating a base F-statistic that describes the correlation of the explanatory variables with the response variables, and then randomly scrambling the order of the explanatory variables to break any existing correlation a large number of times and creating an F statistic from the scrambled data. The number of scrambled-F statistics that are more extreme than the original F statistic can be used to calculate a P-statistic.\nH0: The mean and spread of count.max.duplicates and num.consecutive do not differ between sequences created by humans and sequences created by a computer.\nHA: The mean or spread of count.max.duplicates or num.consecutive differ between sequences created by humans and sequences created by a computer.\ndists \u0026lt;- features %\u0026gt;% select(count.max.duplicates, num.consecutive) %\u0026gt;% dist() adonis(dists~Is.Human,data=features, permutations = 9999) ## ## Call: ## adonis(formula = dists ~ Is.Human, data = features, permutations = 9999) ## ## Permutation: free ## Number of permutations: 9999 ## ## Terms added sequentially (first to last) ## ## Df SumsOfSqs MeanSqs F.Model R2 Pr(\u0026gt;F) ## Is.Human 1 34.6 34.600 16.108 0.07523 1e-04 *** ## Residuals 198 425.3 2.148 0.92477 ## Total 199 459.9 1.00000 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 The p-value of 1e-4 is smaller than the significance level of 0.10, so we may reject the null hypothesis and conclude that there is actually a difference between the distributions of these two variables in different source groups.\nA plot showing the location of the test statistic on the dist distribution is shown bellow.\nggplot(data.frame(\u0026quot;dists\u0026quot; = as.numeric(dists)), aes(x=dists)) + geom_histogram(binwidth = 0.4, boundary = 0) + geom_vline(xintercept = quantile(dists, 1e-04))  Linear Regression We will now perform a linear regression predicting Is.Human from count.max.duplicates and num.consecutive.\nRunning Linear Regression (with interaction) The first step is to create mean centered versions of these variables.\nfeatures \u0026lt;- features %\u0026gt;% mutate(\u0026quot;count.max.duplicates_c\u0026quot; = count.max.duplicates - mean(count.max.duplicates), \u0026quot;num.consecutive_c\u0026quot; = num.consecutive - mean(num.consecutive)) Now we can create a linear model.\nmodel \u0026lt;- lm(Is.Human ~ count.max.duplicates_c * num.consecutive_c, data = features) summary(model) ## ## Call: ## lm(formula = Is.Human ~ count.max.duplicates_c * num.consecutive_c, ## data = features) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.77651 -0.38664 -0.01848 0.39944 1.12937 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 5.000e-01 3.313e-02 15.091 ## count.max.duplicates_c -2.139e-01 5.189e-02 -4.123 ## num.consecutive_c 8.801e-02 2.415e-02 3.644 ## count.max.duplicates_c:num.consecutive_c 6.333e-05 3.472e-02 0.002 ## Pr(\u0026gt;|t|) ## (Intercept) \u0026lt; 2e-16 *** ## count.max.duplicates_c 5.53e-05 *** ## num.consecutive_c 0.000343 *** ## count.max.duplicates_c:num.consecutive_c 0.998547 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.4666 on 196 degrees of freedom ## Multiple R-squared: 0.1464, Adjusted R-squared: 0.1333 ## F-statistic: 11.21 on 3 and 196 DF, p-value: 8.074e-07 The intercept is the average value of the Is.Human variable (1 for human, 0 for computer). This is 0.5 since there are the same number of human generated sequences as computer generated sequences. The coefficient for the max number of duplicates is -0.21. This means that for every additional duplicate greater than the mean, the predicted probability that it was created by a human is decreased by 21%. The coefficient for the number of consecutive numbers is 0.088. This means that for every additional consecutive number above the mean, the predicted probability that it was created by a human increases by 8.8%. The coefficient for the interaction between the two variables is 6.33e-5. This means that for every increase of value in the number of duplicates, the coefficient of the number of consecutive digits is increased by 6.33e-5 (this is a super small value and is not significantly different from 0, so interaction can be ignored going forward).\nline_x \u0026lt;- seq(from = 1.6, to = 5.3, length.out = 200) line \u0026lt;- (-1 * (line_x - mean(features$count.max.duplicates)) * -2.139e-01) / 8.801e-02 + mean(features$num.consecutive) ggplot(features, aes(x = count.max.duplicates, y = num.consecutive)) + #scale_x_continuous(limits=c(1.7,5.3)) + #scale_y_continuous(limits=c(-0.3,7.3)) + geom_ribbon(aes(x = line_x, ymax= if_else(line \u0026lt; 7.3, line, 7.3), ymin=-0.4, alpha = 0.2, fill = \u0026quot;Computer\u0026quot;)) + geom_ribbon(aes(x = line_x, ymax= 7.3, ymin=if_else(line \u0026lt; 7.3, line, 7.3), alpha = 0.2, fill = \u0026quot;Human\u0026quot;))+ geom_jitter(width = 0.35, height = 0.35, aes(color = if_else(Is.Human == 1, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;))) + geom_point(aes(color = if_else(Is.Human == 1, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;))) + labs(color = \u0026quot;Source\u0026quot;, fill = \u0026quot;Predicted as\u0026quot;, title = \u0026quot;Regression of Significant variables\u0026quot;) + xlab(\u0026quot;Maximum number of duplicate digits\u0026quot;) + ylab(\u0026quot;Number of consecutive digits\u0026quot;) + scale_alpha(guide = \u0026quot;none\u0026quot;)  Checking Assumptions It is likely the assumption of linearity fails as there does not appear to be a very strong linear relationship. Additionally, the scatterplot does not seem to be very normally distributed as the values for maximum number of duplicate digits are grouped on the left.\n Testing with Robust Standard Errors We can use the coeftest method to perform a test on the linear regression model to get more cautious p-values.\ncoeftest(model, vcov=vcovHC(model)) ## ## t test of coefficients: ## ## Estimate Std. Error t value ## (Intercept) 5.0001e-01 3.4904e-02 14.3253 ## count.max.duplicates_c -2.1391e-01 6.8146e-02 -3.1390 ## num.consecutive_c 8.8011e-02 2.6788e-02 3.2854 ## count.max.duplicates_c:num.consecutive_c 6.3328e-05 5.3216e-02 0.0012 ## Pr(\u0026gt;|t|) ## (Intercept) \u0026lt; 2.2e-16 *** ## count.max.duplicates_c 0.001957 ** ## num.consecutive_c 0.001206 ** ## count.max.duplicates_c:num.consecutive_c 0.999052 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 With this additional test, nothing changed; the two variables are still significantly correlated with the source of the sequence (p-values of 1.96e-3 and 1.21e-3) and the interaction is still insignificant with p-value 0.999.\n Effect Size With an R2 value of 0.146, the linear regression model explains 14.6% of the variation in the source by the maximum number of duplicates in a sequence and the number of consecutive digits in a sequence.\n Linear Regression Without Interaction We can now run the same linear regression without interactions to see the effect of the interactions.\nmodel_meffects \u0026lt;- lm(Is.Human ~ count.max.duplicates_c + num.consecutive_c, data = features) summary(model_meffects) ## ## Call: ## lm(formula = Is.Human ~ count.max.duplicates_c + num.consecutive_c, ## data = features) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.77657 -0.38664 -0.01865 0.39945 1.12919 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 0.50000 0.03291 15.192 \u0026lt; 2e-16 *** ## count.max.duplicates_c -0.21391 0.05175 -4.133 5.29e-05 *** ## num.consecutive_c 0.08801 0.02405 3.659 0.000325 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.4655 on 197 degrees of freedom ## Multiple R-squared: 0.1464, Adjusted R-squared: 0.1377 ## F-statistic: 16.9 on 2 and 197 DF, p-value: 1.69e-07 The coefficients and R2 values of the model without interaction are almost identical to that of the model with interaction. This can be easily explained by the fact that the model including interaction showed an extremely small level of interaction that was about as insignificant as one can get. We can use a likelihood ratio test to formally show that the models are not statistically different.\nlrtest(model, model_meffects) ## Likelihood ratio test ## ## Model 1: Is.Human ~ count.max.duplicates_c * num.consecutive_c ## Model 2: Is.Human ~ count.max.duplicates_c + num.consecutive_c ## #Df LogLik Df Chisq Pr(\u0026gt;Chisq) ## 1 5 -129.33 ## 2 4 -129.33 -1 0 0.9985 With a p-value of 0.9985, there is no significant difference between the two models.\n  Logistic Regression Wee will now run a logistic regression predicting the source of the random number sequences from the maximum number of duplicate digits and the number of consecutive digits. We can reuse the mean centered variables created when running the linear regression test.\nmodel \u0026lt;- glm(Is.Human ~ count.max.duplicates_c + num.consecutive_c, data = features, family = \u0026quot;binomial\u0026quot;) summary(model) ## ## Call: ## glm(formula = Is.Human ~ count.max.duplicates_c + num.consecutive_c, ## family = \u0026quot;binomial\u0026quot;, data = features) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.76324 -0.96046 -0.01944 0.98549 2.45624 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) -0.000442 0.153774 -0.003 0.997707 ## count.max.duplicates_c -1.004141 0.259436 -3.870 0.000109 *** ## num.consecutive_c 0.423695 0.123276 3.437 0.000588 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 277.26 on 199 degrees of freedom ## Residual deviance: 245.40 on 197 degrees of freedom ## AIC: 251.4 ## ## Number of Fisher Scoring iterations: 3 The coefficients represent the change in the predicted log-odds of the source being human for a 1 unit change in the measurement. The intercept is -4.42e-4. This corresponds to an odd of 1, or a probability of 0.5 of the observation being generated by a human when the other variables are equal to their means. The coefficient of count.max.duplicates_c is -1.00. This means that for every increase of 1 in count.max.duplicates_c, the predicted log-odds of the source being human will decrease by 1.00. The coefficient of num.consecutive_c is 0.424. This means that for every increase in num.consecutive_c of 1, the predicted log-odds of the source being human will increase by 0.424.\nQuality of the Logistic Regression Model We can create a confusion matrix and generate some other relevant statistics using the confusionMatrix function of the caret library (we use {R} positive=\u0026quot;Human\u0026quot; to make a prediction of Human the positive .\ntruth \u0026lt;- factor(if_else(features$Is.Human == 1, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;)) pred \u0026lt;- factor(if_else(as.numeric(predict(model, type = \u0026quot;response\u0026quot;)) \u0026gt; 0.5, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;)) confusionMatrix(truth, pred, positive = \u0026quot;Human\u0026quot;) ## Confusion Matrix and Statistics ## ## Reference ## Prediction Computer Human ## Computer 62 38 ## Human 32 68 ## ## Accuracy : 0.65 ## 95% CI : (0.5795, 0.7159) ## No Information Rate : 0.53 ## P-Value [Acc \u0026gt; NIR] : 0.0003917 ## ## Kappa : 0.3 ## ## Mcnemar\u0026#39;s Test P-Value : 0.5500973 ## ## Sensitivity : 0.6415 ## Specificity : 0.6596 ## Pos Pred Value : 0.6800 ## Neg Pred Value : 0.6200 ## Prevalence : 0.5300 ## Detection Rate : 0.3400 ## Detection Prevalence : 0.5000 ## Balanced Accuracy : 0.6505 ## ## \u0026#39;Positive\u0026#39; Class : Human ##  The accuracy of the model is 0.65: 65% of the observations were predicted correctly. The sensitivity is 0.642: 64.2% of the human generated sequences were correctly identified as such. The specificity is 0.660: 66.0% of the computer generated sequences were correctly identified as such. The recall (positive predicted value) is 0.680: 68.0% of sequences predicted as human generated actually were human generated.\n Density Plot logit\u0026lt;-predict(model) #get predicted log-odds truth\u0026lt;-factor(if_else(features$Is.Human == 1, \u0026quot;Human\u0026quot;, \u0026quot;Computer\u0026quot;)) ggplot(features,aes(x=logit, fill=truth)) + geom_density(alpha=.3) + geom_vline(xintercept=0, lty=2) + labs(title = \u0026quot;Density Plot of Logistic Regression\u0026quot;, fill = \u0026quot;Source\u0026quot;) + xlab(\u0026quot;Predicted Log-odds\u0026quot;) + ylab(\u0026quot;Density\u0026quot;) There is a lot of overlap suggesting that the final model created to classify the source will not be very good. It does imply, however, that we’ll be able to do a little bit better than random guessing since there are portions of the graph that do not overlap.\n ROC and AUC We can now calculate the ROC plot of the logistic model.\nROCplot \u0026lt;- ggplot(features) + geom_roc(aes(d=Is.Human, m=predict(model, type = \u0026quot;response\u0026quot;)), n.cuts=0) + labs(title = \u0026quot;ROC Plot of Logistic Regression Model\u0026quot;) ROCplot The ROC curve is concave down, which is a good sign for the accuracy of the model.\nWe can now calculate AUC, the area under the ROC curve.\ncalc_auc(ROCplot)$AUC ## [1] 0.7232 The AUC is 0.723. This gives the model a fair classification for its ability to be both sensitive and specific.\n Cross Validation We can perform a 10 Fold Cross Validation to determine the out of sample statistics for the model. The dataset was already randomized at the beginning of the project, so this does not need to be done again. The function “diags” described in class will be used to summarize the data.\nset.seed(666) k = 10 folds\u0026lt;-cut(seq(1:nrow(features)),breaks=k,labels=F) diags\u0026lt;-NULL for(i in 1:k){ train\u0026lt;-features[folds!=i,] test\u0026lt;-features[folds==i,] truth\u0026lt;-test$Is.Human fit\u0026lt;- glm(Is.Human ~ count.max.duplicates_c + num.consecutive_c, data = train, family=\u0026quot;binomial\u0026quot;) probs\u0026lt;- predict(fit, newdata = test, type = \u0026quot;response\u0026quot;) diags\u0026lt;-rbind(diags,class_diag(probs,truth)) } apply(diags,2,mean) ## acc sens spec ppv auc ## 0.6200000 0.6283134 0.6417166 0.6620377 0.7073150 The out-of-sample accuracy, sensitivity, and recall (ppv) are 0.620, 0.628, and 0.662. The AUC is 0.707, which is only slightly less than the in-sample AUC, suggesting there was very little overfitting (most likely due to the extensive analysis of which variables were actual predictors before selecting the variables to use in the model).\n  Lasso Regression We will now perform a Lasso regression using every feature gathered about the data.\ny\u0026lt;-as.matrix(features$Is.Human) ###save response variable x\u0026lt;-features %\u0026gt;% select(count.0, count.1, count.2, count.3, count.4, count.5, count.6, count.7, count.8, count.9, count.max.duplicates, num.consecutive, derivative, mean, std.dev, num.odd, num.even) %\u0026gt;% scale %\u0026gt;% as.matrix cv\u0026lt;-cv.glmnet(x,y,family=\u0026quot;binomial\u0026quot;) lasso\u0026lt;-glmnet(x,y,family=\u0026quot;binomial\u0026quot;,lambda=cv$lambda.1se) coef(lasso) ## 18 x 1 sparse Matrix of class \u0026quot;dgCMatrix\u0026quot; ## s0 ## (Intercept) -0.0003727751 ## count.0 . ## count.1 . ## count.2 . ## count.3 . ## count.4 . ## count.5 . ## count.6 . ## count.7 . ## count.8 . ## count.9 . ## count.max.duplicates -0.2112269656 ## num.consecutive 0.1474339995 ## derivative . ## mean . ## std.dev . ## num.odd . ## num.even . Interestingly enough the only predictors with non 0 coefficients are the two predictors we determined to be significant in the previous sections of this project: count.max.duplicates and num.consecutive. For this reason, the 10-fold CV will be exactly the same as the 10-Fold CV in the previous section, and will be excluded.\n Conclusion I found two features of a randomly generated numbers that are significant predictors of whether the sequence of numbers was generated by a human or computer. These two features are the maximum number of times any one digit is repeated in a sequence and the number of consecutive numbers in the digits of a sequence. These two features describe 14.6% of the variation in the source of the sequence, and together can be used to create a logistic model with a 62.0% accuracy and AUC of 0.707. This can be described as a model of fair quality, and is definitely better than guessing.\n ","date":1574726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574726400,"objectID":"46024063f70422803924338d3f5227b9","permalink":"/project/sds328-project2/","publishdate":"2019-11-26T00:00:00Z","relpermalink":"/project/sds328-project2/","section":"project","summary":"A statistical analysis with the goal of predicting the creator of computer and human generated random numbers.","tags":["Data Science"],"title":"Analysis of Computer and Human Generated Random Number Sequences","type":"project"},{"authors":null,"categories":null,"content":" Introduction The datasets I chose to analyze for this project are a dataset of vehicle fuel economies in the United States and a dataset of yearly green house gas emission per country.\nThe dataset of vehicle fuel economies has a row for each make and model of car released in the United States from 1984-2017. The relevant included features for each make and model of car are the year it was released, the type of fuel it uses, the approcximate miles per gallon in the city, on the highway, and combined city and highway driving.\nThe dataset of green house gas emision per country contains a row for every country and a column for every year 1750-2019. Each entry is the number of tonnes of green house gas emitted from that country in that year.\nBoth dataset were found on kaggle.com at the following links:\nVehicle Fuel Economy Estimates, 1984-2017 : https://www.kaggle.com/epa/fuel-economy/ CO2 and GHG emission data : https://www.kaggle.com/srikantsahu/co2-and-ghg-emission-data/   Tidying Let us begin by loading the packages and dataframes we will be using. Emissions (called emissions_wide because we’ll later make it long) and cars were both downloaded from kaggle in .csv form.\nlibrary(tidyverse) # Pivot_long doesn\u0026#39;t work without this...? library(ggplot2) library(dplyr) library(ggthemes) emissions_wide \u0026lt;- read.csv(\u0026quot;emissions.csv\u0026quot;) cars \u0026lt;- read.csv(\u0026quot;cars.csv\u0026quot;) emissions_wide is a dataframe with 231 observations (rows) of 268 variables (columns). The first thing we need to do is make the emissions_wide dataframe long. Instead of having a single column for country name and 267 columns for each year of interest, we want it to have a single column for country name, a single column for the year of the observation, and a single column for the observation itself. We will do this with pivot_longer using names_prefix = \u0026quot;X\u0026quot; to remove the “X” from the begining of every year column name, and a mutate to convert the year column from a character type to a numeric type. We will then use filter to remove all observations that are not of the united states, since the fuel economy data only includes US data. We will then remove the Country column since it is no longer neccessary due to it only containing one value.\nemissions \u0026lt;- emissions_wide %\u0026gt;% pivot_longer(-Country, names_to = \u0026quot;Year\u0026quot;, names_prefix = \u0026quot;X\u0026quot;, values_to = \u0026quot;Yearly.Emissions\u0026quot;) %\u0026gt;% filter(Country == \u0026quot;United States\u0026quot;) %\u0026gt;% mutate(Year = as.numeric(Year)) %\u0026gt;% select(-Country) tail(emissions) # prints the end of the dataframe (The begining is very uninteresting) ## # A tibble: 6 x 2 ## Year Yearly.Emissions ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 2012 372000000000 ## 2 2013 378000000000 ## 3 2014 383000000000 ## 4 2015 389000000000 ## 5 2016 394000000000 ## 6 2017 399000000000 Next, purely to demonstrate the use of pivot_wider we will put emissions back into wide form.\nemWide \u0026lt;- emissions %\u0026gt;% pivot_wider(id_cols = Year, names_from = Year, values_from = Yearly.Emissions) %\u0026gt;% select(\u0026quot;2013\u0026quot;, \u0026quot;2014\u0026quot;, \u0026quot;2015\u0026quot;, \u0026quot;2016\u0026quot;, \u0026quot;2017\u0026quot;) # pick only a few columns to make it viewable head(emWide) ## # A tibble: 1 x 5 ## `2013` `2014` `2015` `2016` `2017` ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 378000000000 383000000000 389000000000 394000000000 399000000000 Now we will clean up the cars dataset to include only the columns we need instead of all 81 columns in it. We will also rename some of the columns and remove all rows with MPG measurements that are 0 (this data set uses 0 instead of NA).\ncarsTidy \u0026lt;- cars %\u0026gt;% rename(City.MPG = Unrounded.City.MPG..FT1., Highway.MPG = Unrounded.Highway.MPG..FT1., Combined.MPG = Unrounded.Combined.MPG..FT1.) %\u0026gt;% select(Vehicle.ID, Year, Make, Fuel.Type, City.MPG, Highway.MPG, Combined.MPG) %\u0026gt;% filter(City.MPG != 0, Highway.MPG != 0, Combined.MPG != 0)  Joining We will now join the datasets on the Year variable using inner join. The purpose of this join is to add a column to the cars dataset that contains the amount of greenhouse gas released by the US the year the car was created. The inner_join method is what we want to use here since it will keep all columns from the first dataset (carsTidy) and add the amount of greenhouse gas emitted to every row based on the year.\ncarsEmissions \u0026lt;- carsTidy %\u0026gt;% inner_join(emissions, by = c(\u0026quot;Year\u0026quot;, \u0026quot;Year\u0026quot;)) Not all the entries in the emissions dataset are used. This is because the emissions dataset has years ranging from 1750-2019 while the car dataset has years ranging from 1984-2017 (this is from the title of the datasets). However, all of the rows of the carsTidy dataset will be maintained in the resultant dataset. This is not a problem as we only care about the car data and emissions data from the date range over which we have data.\n Wrangling Let’s first examine the numeric variables we are interested in.\ncarsEmissions %\u0026gt;% summarise(avgCity = mean(City.MPG), sdCity = sd(City.MPG), avgHighway = mean(Highway.MPG), sdHighway = sd(Highway.MPG), avgCombined = mean(Combined.MPG), sdCombined = sd(Combined.MPG)) ## avgCity sdCity avgHighway sdHighway avgCombined sdCombined ## 1 20.77443 11.20033 27.6541 9.710954 23.29061 10.42525 Let’s now create a variable that is an average of the fuel efficiency of the vehicle.\ncarsEmissions \u0026lt;- carsEmissions %\u0026gt;% mutate(Average.MPG = (City.MPG + Highway.MPG + Combined.MPG) / 3 ) carsEmissions %\u0026gt;% select(City.MPG, Highway.MPG, Combined.MPG, Average.MPG) %\u0026gt;% summarize_all(mean) ## City.MPG Highway.MPG Combined.MPG Average.MPG ## 1 20.77443 27.6541 23.29061 23.90638 Let’s next get a basic idea of the data we are looking at begining with the categorical variable Make.\ncarsEmissions %\u0026gt;% summarise(NumCarEntries=n(), NumUniqueMakes=length(unique(Make))) ## NumCarEntries NumUniqueMakes ## 1 8451 60 There are 8451 entries in carsEmissions and 60 unique entries. Let’s pick just the most common 5 car makes for analyzing.\nsummary(carsEmissions$Make, 6) ## BMW Chevrolet Ford Mercedes-Benz Toyota ## 701 605 592 517 397 ## (Other) ## 5639 commonMake \u0026lt;- carsEmissions %\u0026gt;% filter(Make %in% c(\u0026quot;BMW\u0026quot;, \u0026quot;Chevrolet\u0026quot;, \u0026quot;Ford\u0026quot;, \u0026quot;Mercedes-Benz\u0026quot;, \u0026quot;Toyota\u0026quot;)) We can group by make and Fuel.Type and then summarize with the mean average MPG.\ncommonMake %\u0026gt;% group_by(Make) %\u0026gt;% summarise(mean = mean(Average.MPG), count = n(), sd = sd(Average.MPG), min = min(Average.MPG), max = max(Average.MPG)) %\u0026gt;% arrange(desc(mean)) %\u0026gt;% head() ## # A tibble: 5 x 6 ## Make mean count sd min max ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Toyota 25.0 397 9.90 14.6 76.1 ## 2 BMW 23.6 701 9.88 14.4 124. ## 3 Ford 23.5 592 10.3 11.3 107. ## 4 Chevrolet 22.8 605 10.0 12.0 119. ## 5 Mercedes-Benz 21.4 517 6.89 10.8 83.7 commonMake %\u0026gt;% group_by(Make, Fuel.Type) %\u0026gt;% summarise(mean = mean(Average.MPG), count = n(), sd = sd(Average.MPG), min = min(Average.MPG), max = max(Average.MPG)) %\u0026gt;% arrange(desc(mean)) %\u0026gt;% head() ## # A tibble: 6 x 7 ## # Groups: Make [5] ## Make Fuel.Type mean count sd min max ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 BMW Electricity 119. 6 9.14 102. 124. ## 2 Chevrolet Electricity 119. 4 0.0860 119. 119. ## 3 Ford Electricity 105. 6 1.02 105. 107. ## 4 Mercedes-Benz Electricity 83.7 4 0.00745 83.7 83.7 ## 5 Toyota Electricity 76.1 3 0 76.1 76.1 ## 6 Toyota Regular Gas and Electricity 50.6 5 2.04 49.7 54.2 We can see that out of the five companies that created the greatest number of car models, Toyota cars have the best gas milege and Mercedes-Benz have the worst. However, when including the type of fuel a car uses as a grouping variable, we see that the top 5 most fuel efficient vehicles are electric cars (makes sense).\nLet’s see which make and class of car has the biggest average difference in city and highway fuel efficiency.\ncommonMake %\u0026gt;% group_by(Make) %\u0026gt;% summarise(diff = mean(abs(City.MPG - Highway.MPG)), count = n(), sdDiff = sd(abs(City.MPG - Highway.MPG))) %\u0026gt;% arrange(desc(diff)) %\u0026gt;% head() ## # A tibble: 5 x 4 ## Make diff count sdDiff ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 BMW 8.48 701 2.33 ## 2 Chevrolet 7.41 605 2.50 ## 3 Ford 7.09 592 2.28 ## 4 Mercedes-Benz 7.04 517 1.91 ## 5 Toyota 5.24 397 2.00 commonMake %\u0026gt;% group_by(Make, Fuel.Type) %\u0026gt;% summarise(diff = mean(abs(City.MPG - Highway.MPG)), count = n(), sdDiff = sd(abs(City.MPG - Highway.MPG))) %\u0026gt;% arrange(desc(diff)) %\u0026gt;% head() ## # A tibble: 6 x 5 ## # Groups: Make [3] ## Make Fuel.Type diff count sdDiff ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 BMW Electricity 22.9 6 6.31 ## 2 Chevrolet Electricity 18.6 4 0.820 ## 3 Ford Electricity 13.0 6 4.73 ## 4 Chevrolet Diesel 11.4 6 4.58 ## 5 BMW Diesel 9.61 29 2.16 ## 6 BMW Premium 8.41 653 1.64 BMW cars, and more specifically BMW electric cars have the biggest difference in fuel efficiency from higway to city driving.\ncor(carsEmissions$Average.MPG, carsEmissions$Yearly.Emissions) ## [1] 0.1348772 The Average.MPG variable and the Yearly.Emissions variable are very weakly linearly positively correlated.\ncor(carsEmissions$Year, carsEmissions$Average.MPG) ## [1] 0.1343623 The Year and Average.MPG variable are also weakly linearly correlated.\ncor(carsEmissions$Year, carsEmissions$Yearly.Emissions) ## [1] 0.999662 There is a very strong correlation between Year and Yearly.Emissions.\ncarsEmissions %\u0026gt;% select(City.MPG, Highway.MPG, Combined.MPG, Average.MPG, Year, Yearly.Emissions) %\u0026gt;% cor() ## City.MPG Highway.MPG Combined.MPG Average.MPG Year ## City.MPG 1.0000000 0.9593124 0.9942326 0.9923557 0.1203128 ## Highway.MPG 0.9593124 1.0000000 0.9833193 0.9867523 0.1495610 ## Combined.MPG 0.9942326 0.9833193 1.0000000 0.9997035 0.1324977 ## Average.MPG 0.9923557 0.9867523 0.9997035 1.0000000 0.1343623 ## Year 0.1203128 0.1495610 0.1324977 0.1343623 1.0000000 ## Yearly.Emissions 0.1207456 0.1501808 0.1329924 0.1348772 0.9996620 ## Yearly.Emissions ## City.MPG 0.1207456 ## Highway.MPG 0.1501808 ## Combined.MPG 0.1329924 ## Average.MPG 0.1348772 ## Year 0.9996620 ## Yearly.Emissions 1.0000000 We can see from all of the summary statistics above that there are a lot of different Makes of car and that the fuel efficiency varaies between different Makes of car a little, and between different fuel types a lot. The only interesting correlation between two numerics is the strong positive correlation between Year and Yearly.Emmissions; Emissions increase over time. I was expecting a higher correlation between year and the three different MPG observations.\n Visualizing carsEmissions \u0026lt;- carsEmissions %\u0026gt;% mutate(Common.Fuel.Type = ifelse(Fuel.Type == \u0026quot;Regular\u0026quot;, \u0026quot;Regular\u0026quot;, ifelse(Fuel.Type == \u0026quot;Premium\u0026quot;, \u0026quot;Premium\u0026quot;, ifelse(Fuel.Type == \u0026quot;Gasoline or E85\u0026quot;, \u0026quot;Gasoline or E85\u0026quot;, ifelse(Fuel.Type == \u0026quot;Electricity\u0026quot;, \u0026quot;Electricity\u0026quot;, \u0026quot;Other\u0026quot; ))))) ggplot(carsEmissions, aes(x = Year, y = Average.MPG, color = Common.Fuel.Type)) + ylab(\u0026quot;Average MPG\u0026quot;) + xlab(\u0026quot;Year\u0026quot;) + geom_point() + geom_jitter(width = 0.2) + labs(title = \u0026quot;Average Miles Per Gallon by Fuel Type\u0026quot;, color = \u0026quot;Fuel Type\u0026quot;) + geom_smooth(method = \u0026quot;lm\u0026quot;, fill = NA) + theme_stata() + theme(plot.title = element_text(color = \u0026quot;darkblue\u0026quot;)) This graph shows the change in the Average MPG of cars grouped by the type of fuel that they consume. There are many fuel types in the dataset, so only the most common four are labeled with their own names. The others are grouped into an other category. We can see from the best fit lines for each group that the fuel efficiency increased on average over the years for every fuel type. We can also see that electric cars are the only fuel type for which the average miles per gallon is distinguishable from the other groups and that it is much higher than the other groups.\ncarsEmissions \u0026lt;- carsEmissions %\u0026gt;% mutate(Common.Make = ifelse(Make == \u0026quot;BMW\u0026quot;, \u0026quot;BMW\u0026quot;, ifelse(Make == \u0026quot;Chevrolet\u0026quot;, \u0026quot;Chevrolet\u0026quot;, ifelse(Make == \u0026quot;Ford\u0026quot;, \u0026quot;Ford\u0026quot;, ifelse(Make == \u0026quot;Mercedes-Benz\u0026quot;, \u0026quot;Mercedes-Benz\u0026quot;, \u0026quot;Other\u0026quot; ))))) carsEmissions_long \u0026lt;- carsEmissions %\u0026gt;% select(Common.Make, City.MPG, Highway.MPG, Combined.MPG) %\u0026gt;% pivot_longer(-Common.Make, names_to = \u0026quot;Measurement\u0026quot;, values_to = \u0026quot;Value\u0026quot;, names_pattern = \u0026quot;(.*).MPG\u0026quot;) ggplot(carsEmissions_long, aes(x=Common.Make)) + xlab(\u0026quot;Make of Vehicle\u0026quot;) + ylab(\u0026quot;MPG\u0026quot;) + labs(title = \u0026quot;Fuel Efficiency of Vehicles by Make\u0026quot;, color = \u0026quot;Measurement Type\u0026quot;) + geom_point(aes(y=Value, color = Measurement),stat=\u0026quot;summary\u0026quot;, size = 4) + scale_y_continuous(breaks = seq(from=14, to=30, by=2)) + theme_clean() + theme(plot.title = element_text(colour = \u0026quot;gray8\u0026quot;)) This graph shows three different measures of fuel efficiency for each Make of vehicle. It was created by using pivot_long on the carsEmissions dataset to make a categorical variable for the type of the measurement of fuel efficiency. Only the four most common makes in the dataset were included with the rest being grouped into an “Other” group. We can see that Mercedez-Benz has the worst fuel efficiency for all three measurements, and BMW has the best highway performance while Ford has the best city performance (out of only the four most common Makes).\n Dimensionality Reduction comps \u0026lt;- carsEmissions %\u0026gt;% select(Year, City.MPG, Highway.MPG, Combined.MPG, Average.MPG, Yearly.Emissions) %\u0026gt;% prcomp() summary(comps) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 ## Standard deviation 1.087e+10 20.59 2.087 0.1999 0.05232 1.061e-10 ## Proportion of Variance 1.000e+00 0.00 0.000 0.0000 0.00000 0.000e+00 ## Cumulative Proportion 1.000e+00 1.00 1.000 1.0000 1.00000 1.000e+00 compsdf \u0026lt;- as.data.frame(comps$x) compsdf$Common.Fuel.Type = carsEmissions$Common.Fuel.Type ggplot(compsdf, aes(x = PC2, y = PC3, color=Common.Fuel.Type)) + labs(title = \u0026quot;PCA Plot Clustered by Fuel Type\u0026quot;, color = \u0026quot;Fuel Type\u0026quot;) + geom_point() rot \u0026lt;- as.data.frame(comps$rotation) rot$feature \u0026lt;- row.names(rot) ggplot(rot, aes(x = PC2, y = PC3, label = feature, color = feature)) + geom_point(size = 3) + labs(title = \u0026quot;Loadings Plot of Numeric Variables\u0026quot;, color = \u0026quot;Variable\u0026quot;) + xlim(-1,1) + ylim(-1,1) The most correlated variables are Combined.MPG and Average.MPG (this makes sense since the combined mpg can be expected to be about the average of Highway and City MPGs). Yearly Emissions is not correlated with the MPG. City.MPG and Highway.MPG show almost no correlation.\n ","date":1571529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571529600,"objectID":"232aa24dd969e7c826c4d0e123a95dc1","permalink":"/project/sds328-project1/","publishdate":"2019-10-20T00:00:00Z","relpermalink":"/project/sds328-project1/","section":"project","summary":"A statistical analysis of vehicle fuel economy using multuple datasets.","tags":["Data Science"],"title":"Analysis of Vehicle Fuel Economies","type":"project"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\"data.csv\") data.head() ``` renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file and adding markup: mmark to your page front matter.\nTo render inline or block math, wrap your LaTeX math with $$...$$.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ renders as\n\\[\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}\\]\nExample inline math $$\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2$$ renders as \\(\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2\\) .\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$ renders as\n\\[f(k;p_0^*) = \\begin{cases} p_0^* \u0026 \\text{if }k=1, \\\\ 1-p_0^* \u0026 \\text {if }k=0.\\end{cases}\\]\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD; A--B; A--C; B--D; C--D; ``` renders as\ngraph TD; A--B; A--C; B--D; C--D; An example sequence diagram:\n```mermaid sequenceDiagram participant Alice participant Bob Alice-John: Hello John, how are you? loop Healthcheck John-John: Fight against hypochondria end Note right of John: Rational thoughts prevail... John--Alice: Great! John-Bob: How about you? Bob--John: Jolly good! ``` renders as\nsequenceDiagram participant Alice participant Bob Alice-John: Hello John, how are you? loop Healthcheck John-John: Fight against hypochondria end Note right of John: Rational thoughts prevail... John--Alice: Great! John-Bob: How about you? Bob--John: Jolly good! An example Gantt diagram:\n```mermaid gantt dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d another task : 24d ``` renders as\ngantt dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d another task : 24d Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell | renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a Markdown extension for asides, also referred to as notices or hints. By prefixing a paragraph with A\u0026gt;, it will render as an aside. You can enable this feature by adding markup: mmark to your page front matter, or alternatively using the Alert shortcode.\nA\u0026gt; A Markdown aside is useful for displaying notices, hints, or definitions to your readers. renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.\n Did you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Drew Neely"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Drew Neely"],"categories":[],"content":"from IPython.core.display import Image Image(\u0026#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png\u0026#39;) print(\u0026#34;Welcome to Academic!\u0026#34;) Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post's folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Drew Neely"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you'll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute       Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Drew Neely","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["Drew Neely","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An in-progress JavaScript compiler and parser generator that will be integrated with NodeJS to optimize scientific JavaScript programs.","tags":["Computer Science"],"title":"ArcJS","type":"project"}]